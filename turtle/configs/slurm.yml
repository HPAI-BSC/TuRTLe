configurations:
  - type: general-partition
    account: your_account
    qos: your_qos
    output: slurm_output/job_%j.out
    error: slurm_output/job_%j.err
    nodes: 1
    cpus-per-task: 112
    time: "02:00:00"
    exclusive: true
  - type: general-single-node-small
    account: your_account
    qos: your_qos
    output: slurm_output/job_%j.out
    error: slurm_output/job_%j.err
    nodes: 1
    cpus-per-task: 80
    time: "02:00:00"
    gres: gpu:4
    exclusive: true
  - type: general-single-node-large
    account: your_account
    qos: your_qos
    output: slurm_output/job_%j.out
    error: slurm_output/job_%j.err
    nodes: 1
    cpus-per-task: 80
    time: "02:00:00"
    gres: gpu:4
    exclusive: true
  - type: general-multi-node
    account: your_account
    qos: your_qos
    output: slurm_output/job_%j.out
    error: slurm_output/job_%j.err
    nodes: 4
    cpus-per-task: 80
    ntasks-per-node: 1
    time: "02:00:00"
    gres: gpu:4
    exclusive: true
    env:
      SLURM_CPU_BIND: 'none'
      SRUN_CPUS_PER_TASK: '80'
      SLURM_GPUS_PER_TASK: '4'
      USE_SYSTEM_NCCL: '1'
      NUMEXPR_MAX_THREADS: '80'
      NCCL_IB_HCA: 'mlx5_0,mlx5_1,mlx5_4,mlx5_5'
      TRANSFORMERS_OFFLINE: '1'
      HF_DATASETS_OFFLINE: '1'
      TORCH_NCCL_ASYNC_ERROR_HANDLING: '1'
      TRITON_LIBCUDA_PATH: '/usr/local/cuda/compat/lib.real/libcuda.so'
      VLLM_CUDA_MEM_ALIGN_KV_CACHE: '1'
      TIMEOUT_HEAD: '300'
      TIMEOUT_WORKER: '800'

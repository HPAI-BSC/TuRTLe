benchmark:
  - task: verilog_eval_rtl
    path_data_benchmark: 
    path_dataset_test:
    path_temporary_files: /your_path
    path_model: /your_path
    metric_output_path: /your_path
    singularity_image: /your_path
    evaluation_image: /your_path
    models:
      - name: CodeV-CL-7B
        multinode: False
        max_length_generation: 2048
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
        prompt: codellama
      - name: CodeV-DS-6.7B
        multinode: False
        max_length_generation: 2048
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: CodeV-QW-7B
        multinode: False
        max_length_generation: 2048
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: deepseek-coder-6.7b-instruct
        multinode: False
        max_length_generation: 2048
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: HaVen-CodeQwen
        multinode: False
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: OpenCoder-8B-Instruct
        multinode: False
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: deepseek-coder-33b-instruct
        multinode: False
        max_length_generation: 2048
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: DeepSeek-R1-Distill-Qwen-14B
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 16384
        temperature: [0.2]
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-32B-Instruct
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-7B-Instruct
        multinode: False
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-14B-Instruct
        multinode: False
        slurm_config: general-single-node-small
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-32B-Instruct
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: RTLCoder-Deepseek-v1.1
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: RTLCoder-Mistral-v1.1
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: starchat2-15b-v0.1
        multinode: False
        slurm_config: general-single-node-large
        max_tokens: 2048
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Origen_merged
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: 0
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: gemma-3-27b-it
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Seed-Coder-8B-Instruct
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_length_generation: 2048
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Seed-Coder-8B-Reasoning-bf16
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_tokens: 16384
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: CodeV-R1-Distill-Qwen-7B
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_tokens: 16384
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: DeepCoder-14B-Preview
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_tokens: 16384
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: QwQ-32B
        slurm_config: general-single-node-large
        temperature: [0.2]
        max_tokens: 16384
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Llama-3.3-70B-Instruct
        max_length_generation: 2048
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-72B-Instruct
        max_length_generation: 2048
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: neuralmagic_Meta-Llama-3.1-405B-Instruct-FP8
        max_length_generation: 2048
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: CodeLlama-70b-Instruct-hf
        max_length_generation: 2048
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: DeepSeek-R1-0528
        max_tokens: 16384
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: DeepSeek-R1
        max_tokens: 16384
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen3-235B-A22B
        max_tokens: 16384
        slurm_config: general-multi-node
        temperature: [0.2]
        top_p: 0.95
        top_k: -1
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        few_shot: 0
        precision: bf16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True

benchmark:
  - task: RTLRepo
    path_dataset_test: /your_path
    rtlrepo_use_train_ds: False
    path_model: /your_path
    metric_output_path: /your_path
    singularity_image: /your_path
    models:
      - name: CodeV-CL-7B
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 256
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: CodeV-DS-6.7B
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 256
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: CodeV-QW-7B
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: deepseek-coder-6.7b-base
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 256
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: deepseek-coder-33b-base
        multinode: False
        slurm_config: general-single-node-large
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: DeepSeek-R1-Distill-Qwen-14B
        multinode: False
        slurm_config: general-single-node-large
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: OriGen_Fix_merged
        multinode: False
        slurm_config: general-single-node-large
        tensor_parallel_size: 1
        max_length_generation: 4096
        gpu_memory_utilization: 0.95
        swap_space: 50
        max_tokens: 50
        temperature: [0.2]
        top_k: 50
        n_samples: 5
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Origen_merged
        multinode: False
        slurm_config: general-single-node-large
        tensor_parallel_size: 1
        max_length_generation: 4096
        gpu_memory_utilization: 0.95
        swap_space: 50
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: HaVen-CodeQwen
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: OpenCoder-8B-Base
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-32B
        multinode: False
        slurm_config: general-single-node-large
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-7B
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-14B
        multinode: False
        slurm_config: general-single-node-large
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 64
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: Qwen2.5-Coder-32B
        multinode: False
        slurm_config: general-single-node-large
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        swap_space: 50
        continuous_batching_size: 16
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: RTLCoder-Deepseek-v1.1
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 32
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: RTLCoder-Mistral-v1.1
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 32
        precision: fp16
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
      - name: starchat2-15b-v0.1
        multinode: False
        slurm_config: general-single-node-small
        max_length_generation: 8192
        max_tokens: 50
        temperature: [0.2]
        n_samples: 5
        continuous_batching_size: 32
        precision: fp16
        gpu_memory_utilization: 0.9
        save_generations: True
        save_metrics: True
        save_references: False
        trust_remote_code: True
